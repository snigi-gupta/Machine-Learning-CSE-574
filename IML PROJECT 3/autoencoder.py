# -*- coding: utf-8 -*-
"""autoencoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NYNVubfkMu6ough-HAij77lfRUUEojax
"""

# import util_mnist_reader as mnist_reader
import tensorflow
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
from keras.datasets import mnist
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Input, UpSampling2D, Reshape, BatchNormalization
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# mount google drive
from google.colab import drive
drive.mount('/content/gdrive')

# read the data
(X_train, Y_train), (X_test, Y_test) = tensorflow.keras.datasets.fashion_mnist.load_data()

# X_train, Y_train = mnist_reader.load_mnist('data/fashion', kind='train')
# X_test, Y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')

# normalize the data
X_train = X_train/255
X_test = X_test/255

# get the number of clusters
clusters = len(np.unique(Y_train))
print(clusters)

"""# Part 1 (K-Means)"""

# reshape data
X_train =  X_train.reshape((-1,784))
X_test =  X_test.reshape((-1,784))

k_means = KMeans(n_clusters=clusters, n_init=20, n_jobs=-1).fit(X_train)
Y_pred_kmeans = k_means.predict(X_test)

# map the actual labels with cluster labels 
from sklearn.utils.linear_assignment_ import linear_assignment

Y_int = Y_test.astype(np.int64)
D = max(Y_pred_kmeans.max(), Y_int.max()) + 1
w = np.zeros((D, D), dtype=np.int64)
# Confusion matrix.
for i in range(Y_pred_kmeans.size):
    w[Y_pred_kmeans[i], Y_int[i]] += 1
ind = linear_assignment(-w)
acc = sum([w[i, j] for i, j in ind]) * 1.0 / Y_pred_kmeans.size

# print accuracy
acc

# print cluster label and actual label mapping
cluster_mapping = ind
print("Cluster Value\t\tActual Label\n")
for c in cluster_mapping:
  print("{}\t\t\t{}\n".format(c[0],c[1]))

# print confusion matrix
import seaborn as sns
import sklearn.metrics
import matplotlib.pyplot as plt
sns.set(font_scale=3)
confusion_matrix = sklearn.metrics.confusion_matrix(Y_pred_kmeans, Y_test)

img_save_name = 'kmeans_matrix_final.png'
path = F"/content/gdrive/My Drive/Colab Notebooks/{img_save_name}" 
plt.figure(figsize=(15, 13))
sns.heatmap(confusion_matrix, annot=True, fmt="d", annot_kws={"size": 20});
plt.title("Confusion matrix", fontsize=30)
plt.ylabel('Clustering label', fontsize=25)
plt.xlabel('True label', fontsize=25)
# plt.show()
plt.savefig(path)

# print classification report (wrong classification report since labelling is not mapped with cluster labels.)
classes = ['top','trouser','pullover','dress','coat','sandal','shirt','sneaker','bag','ankle boot']
print('\nClasification report:\n', classification_report(Y_test, Y_pred_kmeans, target_names=classes))

# mapping the labels for Y_pred_kmeans
Y_pred_kmeans_new = [ind[val][1]for val in Y_pred_kmeans]

# printing classification report with correct cluster labels
classes = ['top','trouser','pullover','dress','coat','sandal','shirt','sneaker','bag','ankle boot']
print('\nClasification report:\n', classification_report(Y_test, Y_pred_kmeans_new, target_names=classes))

# printing clusters
sklearn_pca = PCA(n_components = 2)
pca = sklearn_pca.fit(X_train.reshape((-1,784)))
Y_sklearn = pca.transform(X_train.reshape((-1,784)))
test_sklearn = pca.transform(X_test.reshape((-1,784)))
kmeans = KMeans(n_clusters=10, max_iter=600, algorithm = 'auto')
fitted = kmeans.fit(Y_sklearn)
prediction = kmeans.predict(test_sklearn)
plt.figure(figsize = (10,8))

from scipy.spatial.distance import cdist
def plot_kmeans(kmeans, X, n_clusters=10, rseed=0, ax=None):
    labels = kmeans.fit_predict(X)

    # plot the input data
    ax = ax or plt.gca()
    ax.axis('equal')
    ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)

    # plot the representation of the KMeans model
    centers = kmeans.cluster_centers_
    radii = [cdist(X[labels == i], [center]).max()
             for i, center in enumerate(centers)]
    for c, r in zip(centers, radii):
        ax.add_patch(plt.Circle(c, r, fc='#CCCCCC', lw=3, alpha=0.5, zorder=1))
        
plot_kmeans(kmeans, test_sklearn)

"""# Part 2 (Autoencoder with kmeans)"""

# reshape data for Task 2
X_train = X_train.reshape((-1,28,28,1))
X_test = X_test.reshape((-1,28,28,1))
print(X_train.shape)
print(X_test.shape)

# create model for autoencoder
auto_encoder = Sequential()


auto_encoder.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1), padding='same'))
auto_encoder.add(MaxPooling2D( (2, 2), padding='same'))
auto_encoder.add(Conv2D(16, (3, 3), activation='relu', padding='same'))
auto_encoder.add(MaxPooling2D( (2, 2), padding='same'))
auto_encoder.add(Conv2D(8, (3, 3), strides=(2,2), activation='relu', padding='same'))

# flatten encoding for visualization
auto_encoder.add(Flatten())
auto_encoder.add(Reshape((4, 4, 8)))

auto_encoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))
auto_encoder.add(UpSampling2D((2, 2)))
auto_encoder.add(Conv2D(16, (3, 3), activation='relu', padding='same'))
auto_encoder.add(UpSampling2D((2, 2)))
auto_encoder.add(Conv2D(32, (3, 3), activation='relu'))
auto_encoder.add(UpSampling2D((2, 2)))
auto_encoder.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))

print(auto_encoder.summary())

# auto_encoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])
# auto_encoder.fit(X_train, X_train, epochs=20, batch_size=128)

encoder = Model(inputs=auto_encoder.input, outputs=auto_encoder.get_layer('flatten').output)
encoder.summary()

# training the model
auto_encoder.compile(optimizer='adam', loss='binary_crossentropy')
auto_encoder.fit(X_train, X_train, epochs=50, batch_size=128, validation_data=(X_test, X_test), shuffle=True)

# saving the model
model_save_name = 'kmeans_model_final.hdf5'
path = F"/content/gdrive/My Drive/Colab Notebooks/{model_save_name}" 

auto_encoder.save_weights(path)
print("model saved")

# using kmeans for prediction
features = encoder.predict(X_train)
k_means = KMeans(n_clusters=clusters, n_init=20, n_jobs=-1).fit(features)
Y_pred_kmeans = k_means.predict(encoder.predict(X_test))

# map the actual labels with cluster labels 
from sklearn.utils.linear_assignment_ import linear_assignment

Y_int = Y_test.astype(np.int64)
D = max(Y_pred_kmeans.max(), Y_int.max()) + 1
w = np.zeros((D, D), dtype=np.int64)
# Confusion matrix.
for i in range(Y_pred_kmeans.size):
    w[Y_pred_kmeans[i], Y_int[i]] += 1
ind = linear_assignment(-w)
acc = sum([w[i, j] for i, j in ind]) * 1.0 / Y_pred_kmeans.size

acc

# print cluster label and actual label mapping
cluster_mapping = ind
print("Cluster Value\t\tActual Label\n")
for c in cluster_mapping:
  print("{}\t\t\t{}\n".format(c[0],c[1]))

# print confusion matrix
import seaborn as sns
import sklearn.metrics
import matplotlib.pyplot as plt
sns.set(font_scale=3)
confusion_matrix = sklearn.metrics.confusion_matrix(Y_pred_kmeans, Y_test)

img_save_name = 'kmeans_matrix_final.png'
path = F"/content/gdrive/My Drive/Colab Notebooks/{img_save_name}" 
plt.figure(figsize=(15, 13))
sns.heatmap(confusion_matrix, annot=True, fmt="d", annot_kws={"size": 20});
plt.title("Confusion matrix", fontsize=30)
plt.ylabel('Clustering label', fontsize=25)
plt.xlabel('True label', fontsize=25)
# plt.show()
plt.savefig(path)

# print classification report (wrong classification report since labelling is not mapped with cluster labels.)
classes = ['top','trouser','pullover','dress','coat','sandal','shirt','sneaker','bag','ankle boot']
print('\nClasification report:\n', classification_report(Y_test, Y_pred_kmeans, target_names=classes))

# mapping the labels for Y_pred_kmeans
Y_pred_kmeans_new = [ind[val][1]for val in Y_pred_kmeans]

# printing classification report with correct cluster labels
classes = ['top','trouser','pullover','dress','coat','sandal','shirt','sneaker','bag','ankle boot']
print('\nClasification report:\n', classification_report(Y_test, Y_pred_kmeans_new, target_names=classes))

# printing visualization of autoencoded image
num_images = 10
np.random.seed(42)
random_test_images = np.random.randint(X_test.shape[0], size=num_images)

encoded_imgs = encoder.predict(X_test)
decoded_imgs = auto_encoder.predict(X_test)

plt.figure(figsize=(18, 4))

for i, image_idx in enumerate(random_test_images):
    # plot original image
    ax = plt.subplot(3, num_images, i + 1)
    plt.imshow(X_test[image_idx].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    
    # plot encoded image
    ax = plt.subplot(3, num_images, num_images + i + 1)
    plt.imshow(encoded_imgs[image_idx].reshape(16, 8))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # plot reconstructed image
    ax = plt.subplot(3, num_images, 2*num_images + i + 1)
    plt.imshow(decoded_imgs[image_idx].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()



"""# Part 3 (Autoencoder with GMM)"""

# using gmm for prediction
features = encoder.predict(X_train)
gmm = GaussianMixture(n_components=clusters).fit(features)
Y_pred_kmeans = gmm.predict(encoder.predict(X_test))

# map the actual labels with cluster labels 
from sklearn.utils.linear_assignment_ import linear_assignment

Y_int = Y_test.astype(np.int64)
D = max(Y_pred_kmeans.max(), Y_int.max()) + 1
w = np.zeros((D, D), dtype=np.int64)
# Confusion matrix.
for i in range(Y_pred_kmeans.size):
    w[Y_pred_kmeans[i], Y_int[i]] += 1
ind = linear_assignment(-w)
acc = sum([w[i, j] for i, j in ind]) * 1.0 / Y_pred_kmeans.size

acc

# print cluster label and actual label mapping
cluster_mapping = ind
print("Cluster Value\t\tActual Label\n")
for c in cluster_mapping:
  print("{}\t\t\t{}\n".format(c[0],c[1]))

# print confusion matrix
import seaborn as sns
import sklearn.metrics
import matplotlib.pyplot as plt
sns.set(font_scale=3)
confusion_matrix = sklearn.metrics.confusion_matrix(Y_pred_kmeans, Y_test)

img_save_name = 'kmeans_matrix_final.png'
path = F"/content/gdrive/My Drive/Colab Notebooks/{img_save_name}" 
plt.figure(figsize=(15, 13))
sns.heatmap(confusion_matrix, annot=True, fmt="d", annot_kws={"size": 20});
plt.title("Confusion matrix", fontsize=30)
plt.ylabel('Clustering label', fontsize=25)
plt.xlabel('True label', fontsize=25)
# plt.show()
plt.savefig(path)

# print classification report (wrong classification report since labelling is not mapped with cluster labels.)
classes = ['top','trouser','pullover','dress','coat','sandal','shirt','sneaker','bag','ankle boot']
print('\nClasification report:\n', classification_report(Y_test, Y_pred_kmeans, target_names=classes))

# mapping the labels for Y_pred_kmeans
Y_pred_kmeans_new = [ind[val][1]for val in Y_pred_kmeans]

# printing classification report with correct cluster labels
classes = ['top','trouser','pullover','dress','coat','sandal','shirt','sneaker','bag','ankle boot']
print('\nClasification report:\n', classification_report(Y_test, Y_pred_kmeans_new, target_names=classes))

plt.figure(figsize= (10,8))
plt.plot(auto_encoder.history.history['loss'], '-g', label='Training Loss Track')
plt.plot(auto_encoder.history.history['val_loss'], '-b', label='Validation Loss Track')
plt.legend(loc='upper right')
plt.title('Loss vs Epochs')

